{"metadata":{"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import csv\nfrom datetime import datetime\nimport requests\nfrom bs4 import BeautifulSoup\n\n\ndef get_url(position, location):\n    \"\"\"Generate url from position and location\"\"\"\n    template = 'https://se.indeed.com/jobb?q={}&l={}'\n    position = position.replace(' ', '+')\n    location = location.replace(' ', '+')\n    url = template.format(position, location)\n    return url\n\n\ndef get_record(card):\n    \"\"\"Extract job data from a single record\"\"\"\n    \n    job_title = card.h2.a.get('title')\n    company = card.find('span', 'company').text.strip()\n    job_location = card.find('div', 'recJobLoc').get('data-rc-loc')\n    post_date = card.find('span', 'date').text\n    today = datetime.today().strftime('%Y-%m-%d')\n    summary = card.find('div', 'summary').text.strip().replace('\\n', ' ')\n    job_url = 'https://se.indeed.com' + card.h2.a.get('href')\n\n    # this does not exists for all jobs, so handle the exceptions\n    salary_tag = card.find('span', 'salaryText')\n    if salary_tag:\n        salary = salary_tag.text.strip()\n    else:\n        salary = ''  \n        \n    record = (job_title, company, job_location, post_date, today, summary, salary, job_url)\n    return record\n\n\ndef main(position, location):\n    \"\"\"Run the main program routine\"\"\"\n    records = []\n    url = get_url(position, location)\n    \n    # extract the job data\n    while True:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.text, 'html.parser')\n        cards = soup.find_all('div', 'jobsearch-SerpJobCard')\n        for card in cards:\n            record = get_record(card)\n            records.append(record)\n        try:\n            url = 'https://se.indeed.com' + soup.find('a', {'aria-label': 'NÃ¤sta'}).get('href')\n        except AttributeError:\n            break\n        \n    # save the job data\n    with open('results.csv', 'w', newline='', encoding='utf-8') as f:\n        writer = csv.writer(f)\n        writer.writerow(['JobTitle', 'Company', 'Location', 'PostDate', 'ExtractDate', 'Summary', 'JobUrl'])\n        writer.writerows(records)","metadata":{"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\n# run the main program - in this field you can edit the jobtitle and area - works worldwide to scrape from indeed.com\nmain('Data analyst', 'stockholm')","metadata":{"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}